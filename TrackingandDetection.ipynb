{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tracking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JTFMBic84lH",
        "colab_type": "code",
        "outputId": "8c7574a6-5016-44ab-f9a2-80be98ef1369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!pip install opencv-contrib-python==3.4.8.29"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-contrib-python==3.4.8.29\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/ea/2b3b535e2270b4f69ec27a83ee7499ec6ee8dc17bcd88d89f85707b93c5c/opencv_contrib_python-3.4.8.29-cp36-cp36m-manylinux1_x86_64.whl (34.2MB)\n",
            "\u001b[K     |████████████████████████████████| 34.2MB 88kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.8.29) (1.18.3)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-3.4.8.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAFqhLO5RmLq",
        "colab_type": "code",
        "outputId": "46865b93-a544-42a4-e889-d9ca1e79c22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "from math import cos, sin\n",
        "import numpy as np\n",
        "from keras.layers import Average"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydzLTl2_d4SE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir face_detector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG69SwogRWh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # load our serialized face detector from disk\n",
        "def draw_results_ssd(detected,input_img,ad,img_w,img_h):\n",
        "    \n",
        "    # loop over the detections\n",
        "    if detected.shape[2]>0:\n",
        "        for i in range(0, detected.shape[2]):\n",
        "            confidence = detected[0, 0, i, 2]\n",
        "            # filter out weak detections\n",
        "            if confidence > 0.5:\n",
        "                # compute the (x, y)-coordinates of the bounding box for\n",
        "                # the face and extract the face ROI\n",
        "                (h0, w0) = input_img.shape[:2]\n",
        "                box = detected[0, 0, i, 3:7] * np.array([w0, h0, w0, h0])\n",
        "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "                # print((startX, startY, endX, endY))\n",
        "                x1 = startX\n",
        "                y1 = startY\n",
        "                w = endX - startX\n",
        "                h = endY - startY\n",
        "                \n",
        "                bounding_box_one = (x1,y1,w,h)\n",
        "                bounding_box_one=tuple([int(i) for i in bounding_box_one])\n",
        "\n",
        "                print(bounding_box_one,'--------------------------------------------')\n",
        "\n",
        "                cv2.rectangle(input_img, (startX, startY), (endX, endY),(0, 255, 0))               \n",
        "    \n",
        "    return input_img, bounding_box_one\n",
        "\n",
        "\n",
        "print(\"[INFO] loading face detector...\")\n",
        "protoPath = os.path.sep.join([\"face_detector\", \"deploy.prototxt\"])\n",
        "print('yes1')\n",
        "modelPath = os.path.sep.join([\"face_detector\",\n",
        "    \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
        "print('yes2')\n",
        "net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
        "print('yes3')\n",
        "# capture video\n",
        "cap = cv2.VideoCapture('video.mp4')\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1024*1)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 768*1)\n",
        "detected_pre = np.empty((1,1,1))\n",
        "frame_width = int(cap.get(3)) \n",
        "frame_height = int(cap.get(4)) \n",
        "\n",
        "size = (frame_width, frame_height)\n",
        "result = cv2.VideoWriter('filename.avi',  \n",
        "                      cv2.VideoWriter_fourcc(*'MJPG'), \n",
        "                      10, size) \n",
        "\n",
        "img_idx = 0\n",
        "detected = '' \n",
        "skip_frame = 20 # every 20 frame do 1 detection and network forward propagation\n",
        "ad = 0.6\n",
        "\n",
        "while True:\n",
        "      # get video frame\n",
        "      ret, input_img = cap.read()\n",
        "      if ret == False:\n",
        "          break\n",
        "      \n",
        "      img_idx = img_idx + 1\n",
        "      img_h, img_w, _ = np.shape(input_img)        \n",
        "      if img_idx==1 or img_idx%skip_frame == 0:\n",
        "          blob =cv2.dnn.blobFromImage(cv2.resize(input_img, (300, 300)), 1.0,\n",
        "              (300, 300), (104.0, 177.0, 123.0))\n",
        "          net.setInput(blob)\n",
        "          detected = net.forward()\n",
        "          print(detected.shape,'detected_shape')\n",
        "  \n",
        "          if detected_pre.shape[2] > 0 and detected.shape[2] == 0:\n",
        "                detected = detected_pre\n",
        "          confident = detected[0, 0, 0, 2]\n",
        "            # filter out weak detections\n",
        "          if confident > 0.5:\n",
        "            input_img, bounding_box_one = draw_results_ssd(detected,input_img,ad,img_w,img_h)\n",
        "\n",
        "          tracker = cv2.TrackerCSRT_create()\n",
        "     \n",
        "          print(type(bounding_box_one),\"bounding_box\")\n",
        "          success = tracker.init(input_img, bounding_box_one)\n",
        "      else:            \n",
        "        (success, box) = tracker.update(input_img)\n",
        "        if success:\n",
        "          (x, y, w, h) = [int(v) for v in box]\n",
        "          cv2.rectangle(input_img, (x, y), (x + w, y + h),(0, 255, 0),2)\n",
        "          bounding_box_one = (x, y, w, h)\n",
        "      result.write(input_img)\n",
        "\n",
        "        \n",
        "\n",
        "cap.release()\n",
        "result.release()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImcosXgihE7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}